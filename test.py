import time
import torch
import argparse
import os

from torch.utils.data import DataLoader
from data.dataset import get_dataset
from models.UnifyModel import UnifyModel

# ==========================================
# é…ç½®åŒºåŸŸ (ä¿æŒä¸ train.py ä¸€è‡´)
# ==========================================
default_args = {
    'benchmark': 'xsub',  # å¯¹åº” train.py ä¸­çš„è®¾ç½®
    'modalities': ['rgb', 'pose', 'depth', 'ir'],  # éœ€è¦ä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´
    'num_frames': 32,
    'use_val': False  # æµ‹è¯•è„šæœ¬é€šå¸¸ä¸éœ€è¦å†æ¬¡åˆ‡åˆ† val
}
BATCH_SIZE = 4  # æ¨ç†æ—¶ä¸éœ€è¦æ¢¯åº¦ç´¯ç§¯ï¼ŒBatch Size å¯ä»¥æ ¹æ®æ˜¾å­˜é€‚å½“è°ƒå¤§
CHECKPOINT_PATH = 'work_dir/ggr_experiment/best_model.pth'  # ğŸŸ¢ è¯·ä¿®æ”¹ä¸ºä½ å®é™…çš„æ¨¡å‹è·¯å¾„


def get_test_dataloader(args, batch_size):
    print(f"Loading Test Dataset ({args['benchmark']})...")
    # æ³¨æ„ï¼šè¿™é‡Œ split å¿…é¡»å¡« 'test'
    test_set = get_dataset('NTU120', 'test', args)

    return DataLoader(
        test_set,
        batch_size=batch_size,
        shuffle=False,
        num_workers=8,
        pin_memory=True
    )


def accuracy(output, target, topk=(1,)):
    """è®¡ç®— Top-k å‡†ç¡®ç‡"""
    with torch.no_grad():
        maxk = max(topk)
        batch_size = target.size(0)

        _, pred = output.topk(maxk, 1, True, True)
        pred = pred.t()
        correct = pred.eq(target.view(1, -1).expand_as(pred))

        res = []
        for k in topk:
            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)
            res.append(correct_k.mul_(100.0 / batch_size))
        return res


def main():
    # 1. è§£æå‚æ•° (å¯é€‰ï¼Œä¸ºäº†æ–¹ä¾¿å‘½ä»¤è¡Œä¿®æ”¹æ¨¡å‹è·¯å¾„)
    parser = argparse.ArgumentParser(description='Test Script')
    parser.add_argument('--checkpoint', type=str, default=CHECKPOINT_PATH, help='Path to model checkpoint')
    parser.add_argument('--batch_size', type=int, default=BATCH_SIZE, help='Batch size for testing')
    cmd_args = parser.parse_args()

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ğŸš€ Start Testing | Device: {device} | Checkpoint: {cmd_args.checkpoint}")

    # 2. åŠ è½½æ•°æ®é›†
    test_loader = get_test_dataloader(default_args, cmd_args.batch_size)
    print(f"Data Ready. Test Batches: {len(test_loader)}")

    # 3. æ„å»ºæ¨¡å‹
    # æ³¨æ„ï¼šnum_classes å¿…é¡»ä¸è®­ç»ƒæ—¶ä¸€è‡´ (NTU120=120, NTU60=60)
    model = UnifyModel(num_classes=120).to(device)

    # 4. åŠ è½½æƒé‡
    if os.path.isfile(cmd_args.checkpoint):
        print(f"Loading checkpoint from {cmd_args.checkpoint} ...")
        checkpoint = torch.load(cmd_args.checkpoint, map_location=device)

        # å…¼å®¹ç›´æ¥ä¿å­˜ state_dict æˆ–ä¿å­˜äº†å®Œæ•´ info çš„æƒ…å†µ
        if 'model_state_dict' in checkpoint:
            state_dict = checkpoint['model_state_dict']
        else:
            state_dict = checkpoint

        # å¤„ç†å¯èƒ½çš„ DataParallel 'module.' å‰ç¼€
        new_state_dict = {}
        for k, v in state_dict.items():
            name = k[7:] if k.startswith('module.') else k
            new_state_dict[name] = v

        msg = model.load_state_dict(new_state_dict, strict=True)
        print(f"Checkpoint loaded. {msg}")
    else:
        print(f"Error: No checkpoint found at {cmd_args.checkpoint}")
        return

    # 5. å¼€å§‹æµ‹è¯•
    model.eval()

    top1_acc_avg = 0.0
    top5_acc_avg = 0.0
    total_batches = len(test_loader)
    start_time = time.time()

    with torch.no_grad():
        for i, batch in enumerate(test_loader):
            # æ•°æ®æ¬è¿
            x_rgb = batch['rgb'].to(device)
            x_ir = batch['ir'].to(device)
            x_depth = batch['depth'].to(device)
            x_pose = batch['pose'].to(device)
            targets = batch['label'].to(device)

            # æ¨ç† (gradient_control='base' å³å¯ï¼Œä¸éœ€è¦ GGR è·¯ç”±)
            logits_shared, _ = model(x_rgb, x_ir, x_depth, x_pose, gradient_control='base')

            # è®¡ç®— Batch ç²¾åº¦
            acc1, acc5 = accuracy(logits_shared, targets, topk=(1, 5))
            top1_acc_avg += acc1.item()
            top5_acc_avg += acc5.item()

            if i % 10 == 0:
                print(f"Iter {i}/{total_batches} | Batch Top-1: {acc1.item():.2f}%")

    # 6. æœ€ç»ˆç»“æœ
    top1_acc_avg /= total_batches
    top5_acc_avg /= total_batches
    total_time = time.time() - start_time

    print("\n" + "=" * 40)
    print(f"âœ… Test Finished in {total_time:.1f}s")
    print(f"ğŸ† Top-1 Accuracy: {top1_acc_avg:.2f}%")
    print(f"ğŸ¥ˆ Top-5 Accuracy: {top5_acc_avg:.2f}%")
    print("=" * 40)


if __name__ == '__main__':
    main()